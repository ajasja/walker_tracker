{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import skimage.io as skio\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import trackpy as tp\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_file = r\"D:\\data\\2022-04-26_WALKER_DATA\\AjasjaRollerData\\25C_75mMNaCl_A8fibres\\2B9\\2B9_SingleMolecule_1nM_A8fibres_25C_75mMNaCl_1.tif\"\n",
    "# in_file = r\"D:\\data\\2022-04-26_WALKER_DATA\\AjasjaRollerData\\25C_75mMNaCl_A6fibres\\2B9\\2B9_singlemolecule_1nM_A6fibres_25C_75mMNaCl_1.tif\"\n",
    "# in_file = r\"D:\\data\\2022-04-26_WALKER_DATA\\AjasjaRollerData\\37C_75mMNaCl_A6fibres\\2B9\\2B9_singlemolecule_1nM_A6fibres_37C_75mMNaCl_NoMC_4.tif\"\n",
    "# in_file = r\"D:\\data\\2022-04-26_WALKER_DATA\\2021-09-27__prelim_data\\2B9_SingleMolecule_1nM_A8fibres_25C_75mMNaCl_100-200.tif\"\n",
    "in_file = r'data/20240724-145831_WT_aligned_drift_corrected.tif'\n",
    "\n",
    "basename = os.path.basename(in_file)\n",
    "out_dir = Path(\"data/out/\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_only_walkers_on_fibre_trajectory(in_file, out_dir / basename)\n",
    "basename_noext, ext = os.path.splitext(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method = \"lq\"\n",
    "box_side_length = 9\n",
    "drift = 0\n",
    "min_gradient = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['HDF5_DISABLE_VERSION_CHECK']='0'\n",
    "#TOOD add out parameter\n",
    "!python -m picasso localize {out_dir/basename} --fit-method {fit_method} --box-side-length {box_side_length}  --gradient {min_gradient} --drift {drift}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack -- for now just rename the out file. This is dangerous in multithreaded environment.\n",
    "out_locs = out_dir / (basename_noext + \"_locs.hdf5\")\n",
    "new_suffix = f\"__locs__fit_{fit_method}__box_{box_side_length}__gradient_{min_gradient}__drift_{drift}.hdf5\"\n",
    "new_suffix = (\n",
    "    f\"__locs_{fit_method}_box{box_side_length}_grad{min_gradient}_drift{drift}.hdf5\"\n",
    ")\n",
    "new_out_locs = out_dir / (basename_noext + new_suffix)\n",
    "print(new_out_locs)\n",
    "out_locs.with_suffix(\".yaml\").rename(new_out_locs.with_suffix(\".yaml\"))\n",
    "out_locs.rename(new_out_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_link_displacement_px = 2\n",
    "min_tray_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = pd.read_hdf(new_out_locs, \"locs\")\n",
    "locs[\"mass\"] = locs.photons\n",
    "\n",
    "tray = tp.link(locs, max_link_displacement_px)\n",
    "\n",
    "# count the length of trajectories\n",
    "tray_by_particle = tray.groupby([\"particle\"])\n",
    "tray[\"length\"] = tray_by_particle[\"particle\"].transform(\"count\")\n",
    "\n",
    "print(\"mean drift \", tp.compute_drift(tray).mean())\n",
    "\n",
    "# Exclude very short trays\n",
    "tray = tray.query(f\"length>={min_tray_length}\")\n",
    "\n",
    "steps = tray.groupby([\"particle\"]).apply(get_steps_from_df)\n",
    "steps[\"step_len\"] = np.sqrt(steps.dx**2 + steps.dy**2)\n",
    "\n",
    "suffix = f\"__link{max_link_displacement_px}_traylen{min_tray_length}\"\n",
    "base_linked_tray = Path(f'{new_out_locs.with_suffix(\"\")}{suffix}')\n",
    "tray_out = base_linked_tray.with_suffix(\".tray.csv.gz\")\n",
    "tray.to_csv(tray_out)\n",
    "steps_out = base_linked_tray.with_suffix(\".steps.csv.gz\")\n",
    "steps.to_csv(steps_out)\n",
    "\n",
    "#distribution_check = []\n",
    "steps_matrix = steps[['dx', 'dy']].to_numpy()\n",
    "num_columns = steps_matrix.shape[1]  \n",
    "normal_str = ''\n",
    "for var_idx in range(num_columns):\n",
    "    anderson_data = anderson(steps_matrix[:, var_idx])\n",
    "    is_normal = anderson_data.statistic < anderson_data.critical_values[1]\n",
    "    #distribution_check += [is_normal]\n",
    "    if not is_normal:\n",
    "        normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} NOT normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "    else:\n",
    "        normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "    normal_str += normal \n",
    "\n",
    "info = {}\n",
    "info[\"diff_1D_px_px_frame\"] = float(get_diff_from_steps(steps))\n",
    "\n",
    "px_to_nm = 110\n",
    "frame_to_s = 0.665\n",
    "\n",
    "info[\"diff_1D_nm_nm_s\"] = (\n",
    "    info[\"diff_1D_px_px_frame\"] * px_to_nm * px_to_nm / frame_to_s\n",
    ")\n",
    "info[\"time_per_1000nm_s\"] = 1000 * 1000 / info[\"diff_1D_nm_nm_s\"] / 2\n",
    "\n",
    "info[\"mean_step_nm_s\"] = float(\n",
    "    np.sqrt(2 * info[\"diff_1D_nm_nm_s\"] * frame_to_s) / frame_to_s\n",
    ")\n",
    "\n",
    "diff_info_out = base_linked_tray.with_suffix(\".diff\")\n",
    "\n",
    "info[\"normality_str\"] = normal_str\n",
    "info[\"anderson_test\"] = anderson_data\n",
    "\n",
    "write_yaml(info, diff_info_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = steps['dx']\n",
    "y = steps['dy']\n",
    "bins = (75, 70)\n",
    "hist, xedges, yedges = np.histogram2d(x, y, bins=(75,50), density=True)\n",
    "xcent = (xedges[1:] + xedges[:-1])/2\n",
    "ycent = (yedges[1:] + yedges[:-1])/2\n",
    "x_grid, y_grid = np.meshgrid(xcent, ycent)\n",
    "xy = np.stack((x_grid.ravel(), y_grid.ravel())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2d(xy, x0, y0, sigmax, sigmay, sigmaxy):\n",
    "    if xy.shape[-1] != 2 or len(xy.shape) != 2:\n",
    "        raise ValueError(\"XY data should have shape (n, 2).\")\n",
    "    mu = np.array([x0, y0])\n",
    "    sigma = np.array([[sigmax, sigmaxy], [sigmaxy, sigmay]])\n",
    "    normalization = (((2 * np.pi) ** 2) * np.abs(np.linalg.det(sigma))) ** (-1 / 2)\n",
    "    bell = np.exp(-0.5 * np.sum(((xy - mu) @ np.linalg.inv(sigma)) * (xy - mu), axis=1))\n",
    "    return normalization * bell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess = [0, 0, 1, 1, 0]\n",
    "bounds = ([-np.inf, -np.inf, 0, 0, -1], [np.inf, np.inf, np.inf, np.inf, 1])\n",
    "popt, _ = curve_fit(gaussian_2d, xy, hist.T.ravel(), initial_guess)\n",
    "print(popt)\n",
    "mu = [popt[0], popt[1]]\n",
    "cov_matrix = [[popt[2], popt[4]], [popt[4], popt[3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_str)\n",
    "print(f'the means of multivariate normal distrubution are: mu(dx) = {mu[0]:.3f}, mu(dy) = {mu[1]:.3f}')\n",
    "print(f'the standard deviations of the multivariate normal distribution are: sigma(dx) = {cov_matrix[0][0]:.3f}, sigma(dy) = {cov_matrix[1][1]:.3f}')\n",
    "print(f'the covariance of the multivariate normal distribution is: sigma(dxdy) = {cov_matrix[0][1]:.3f}')\n",
    "print(\"Diff (in px^2/frame): \", info[\"diff_1D_px_px_frame\"])\n",
    "print(\"Diff (in nm^2/s): \", info[\"diff_1D_nm_nm_s\"])\n",
    "print(\"time per 1000nm (s): \", info[\"time_per_1000nm_s\"])\n",
    "print(\"mean step (nm/s):\", info[\"mean_step_nm_s\"])\n",
    "\n",
    "\n",
    "z = gaussian_2d(xy, *popt)\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224, projection='3d')\n",
    "plt.sca(ax1)\n",
    "tray.length.hist()\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Histogram of trajectory steps\")\n",
    "plt.sca(ax2)\n",
    "steps.plot.scatter(\"dx\", \"dy\", alpha=0.1, ax=ax2)\n",
    "plt.title(\"Size of steps\")\n",
    "plt.sca(ax3)\n",
    "plt.hist2d(x,y, bins=bins, density=True)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.contour(x_grid, y_grid, z.reshape(x_grid.shape), cmap='viridis')\n",
    "plt.colorbar(label='probability density')\n",
    "plt.xlabel('dx')\n",
    "plt.ylabel('dy')\n",
    "plt.title('probability density of step sizes - contour plot')\n",
    "plt.sca(ax4)\n",
    "ax4.plot_surface(x_grid, y_grid, z.reshape(x_grid.shape), cmap='viridis')\n",
    "plt.xlabel('dx')\n",
    "plt.ylabel('dy')\n",
    "ax4.set_zlabel('probability')\n",
    "plt.title('Probability density of step sizes - surface plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04975a750d0d94b70e65c12bed027ac01c971320ec0c311113029c4e52a73e0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('picasso')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
