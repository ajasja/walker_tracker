{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import skimage.io as skio\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import trackpy as tp\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import anderson\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = r\"examples\\20240820-111147_WT_multichannel_aligned_drift_corrected.tif\"\n",
    "basename = os.path.basename(in_file)\n",
    "basename_noext, ext = os.path.splitext(basename)\n",
    "out_dir = Path(r\".\\out\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method = \"lq\"\n",
    "box_side_length = 9\n",
    "drift = 0\n",
    "min_gradient = 1000\n",
    "px_to_nm = 72\n",
    "frame_to_s = 0.223\n",
    "\n",
    "max_link_displacement_px = 2\n",
    "max_gap = 2\n",
    "min_tray_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_only_walkers_on_fibre_trajectory(in_file, out_dir / basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out_locs = fit_single_molecules(\n",
    "    out_dir,\n",
    "    basename,\n",
    "    fit_method=fit_method,\n",
    "    box_side_length=box_side_length,\n",
    "    drift=drift,\n",
    "    min_gradient=min_gradient,\n",
    "    px_to_nm=px_to_nm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = pd.read_hdf(new_out_locs, \"locs\")\n",
    "locs[\"mass\"] = locs.photons\n",
    "\n",
    "tray = tp.link(locs, search_range=max_link_displacement_px, memory=max_gap)\n",
    "\n",
    "# count the length of trajectories\n",
    "tray_by_particle = tray.groupby([\"particle\"])\n",
    "tray[\"length\"] = tray_by_particle[\"particle\"].transform(\"count\")\n",
    "dwell_time = tray[\"length\"].mean()\n",
    "\n",
    "print(\"mean drift \", tp.compute_drift(tray).mean())\n",
    "\n",
    "# Exclude very short trays\n",
    "tray = tray.query(f\"length>={min_tray_length}\")\n",
    "\n",
    "steps = tray.groupby([\"particle\"]).apply(get_steps_from_df)\n",
    "steps[\"step_len\"] = np.sqrt(steps.dx**2 + steps.dy**2)\n",
    "\n",
    "suffix = f\"__link{max_link_displacement_px}_traylen{min_tray_length}\"\n",
    "base_linked_tray = Path(f'{new_out_locs.with_suffix(\"\")}{suffix}')\n",
    "tray_out = base_linked_tray.with_suffix(\".tray.csv.gz\")\n",
    "tray.to_csv(tray_out)\n",
    "steps_out = base_linked_tray.with_suffix(\".steps.csv.gz\")\n",
    "steps.to_csv(steps_out)\n",
    "\n",
    "#distribution_check = []\n",
    "steps_matrix = steps[['dx', 'dy']].to_numpy()\n",
    "num_columns = steps_matrix.shape[1]  \n",
    "normal_str = ''\n",
    "for var_idx in range(num_columns):\n",
    "    anderson_data = anderson(steps_matrix[:, var_idx])\n",
    "    is_normal = anderson_data.statistic < anderson_data.critical_values[1]\n",
    "    #distribution_check += [is_normal]\n",
    "    if not is_normal:\n",
    "        normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} NOT normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "    else:\n",
    "        normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "    normal_str += normal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "stack = skio.imread(f'{out_dir}/{basename_noext}.tif')\n",
    "\n",
    "cmap_bright = plt.colormaps.get_cmap(\"Set1\")\n",
    "set1_dict = { particle:cmap_bright(i%9) for i, particle in enumerate(list(set(tray.particle)))}\n",
    "\n",
    "ims = [] \n",
    "\n",
    "fig = plt.figure(\"FRAMES\", dpi=300, frameon=False)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for n in range(stack.shape[0]):\n",
    "    frame = ax.imshow(stack[n].astype('uint16'), cmap = 'Greys_r')\n",
    "    if n in list(set(tray.frame)):\n",
    "        t = []\n",
    "        for k in list(set(tray[(tray[\"frame\"]==n)].particle)):\n",
    "            bright_color = set1_dict[k]\n",
    "            t.append(ax.plot(tray[(tray[\"frame\"]<=n) & (tray[\"particle\"]==k)].x, tray[(tray[\"frame\"]<=n) & (tray[\"particle\"]==k)].y, linewidth=1, color=bright_color))\n",
    "            plt.axis('off')\n",
    "        number = ax.annotate(n,(1,1))\n",
    "        artist_obj = [i[0] for i in t]\n",
    "        artist_obj.append(frame)\n",
    "        artist_obj.append(number)\n",
    "        ims.append(artist_obj)\n",
    "\n",
    "    else:\n",
    "        ims.append([frame])\n",
    "    if n >= 200:\n",
    "        break\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=500, blit=True,repeat_delay=1000)\n",
    "\n",
    "output_path = f'{out_dir}/{basename_noext}_trajectories.mp4'\n",
    "\n",
    "\n",
    "ani.save(output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in set(tray.particle):\n",
    "    plt.plot(tray[tray[\"particle\"]==i].x, tray[tray[\"particle\"]==i].y*-1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Particle trajectories')\n",
    "plt.savefig(f'{out_dir}/{basename}_trajectories.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = steps['dx']\n",
    "y = steps['dy']\n",
    "bins = (75, 70)\n",
    "hist, xedges, yedges = np.histogram2d(x, y, bins=(75,50), density=True)\n",
    "xcent = (xedges[1:] + xedges[:-1])/2\n",
    "ycent = (yedges[1:] + yedges[:-1])/2\n",
    "x_grid, y_grid = np.meshgrid(xcent, ycent)\n",
    "xy = np.stack((x_grid.ravel(), y_grid.ravel())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2d(xy, x0, y0, sigmax, sigmay, sigmaxy):\n",
    "    if xy.shape[-1] != 2 or len(xy.shape) != 2:\n",
    "        raise ValueError(\"XY data should have shape (n, 2).\")\n",
    "    mu = np.array([x0, y0])\n",
    "    sigma = np.array([[sigmax, sigmaxy], [sigmaxy, sigmay]])\n",
    "    normalization = (((2 * np.pi) ** 2) * np.abs(np.linalg.det(sigma))) ** (-1 / 2)\n",
    "    bell = np.exp(-0.5 * np.sum(((xy - mu) @ np.linalg.inv(sigma)) * (xy - mu), axis=1))\n",
    "    return normalization * bell\n",
    "\n",
    "def cov_to_axes_and_rotation(cov, sorted=True):\n",
    "    \"\"\"\"Takes a covariance matrix and returns the principle axes and a rotation\"\"\"\n",
    "    (e1, e2), eigen_vec = np.linalg.eig(cov)\n",
    "    V1,V2 = eigen_vec.T\n",
    "    \n",
    "    # Eigenvectors are assumed to be unit and orthogonal\n",
    "    # print(np.linalg.norm(V1))\n",
    "    e1 = np.real(e1) # sometimes tiny imaginary components are returned. \n",
    "    e2 = np.real(e2) # sometimes tiny imaginary components are returned. \n",
    "    if np.isclose(e1, e2):\n",
    "        # the angle is not well defined\n",
    "        theta = 0\n",
    "\n",
    "    else:\n",
    "        # Are eigenvectors always normalized? \n",
    "        theta = np.degrees(np.arctan2(V1[1], V1[0]))\n",
    "    #if theta>90 and theta <180:\n",
    "    #     theta = 180 - theta\n",
    "    #print(theta)\n",
    "\n",
    "    if sorted: #make sure e1 is always the largest\n",
    "        if e2>e1:\n",
    "            (e1, e2) = (e2, e1)\n",
    "            theta = theta + 90\n",
    "\n",
    "    return e1, e2, np.mod(theta, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess = [0, 0, 1, 1, 0]\n",
    "bounds = ([-np.inf, -np.inf, 0, 0, -1], [np.inf, np.inf, np.inf, np.inf, 1])\n",
    "try:\n",
    "    popt, _ = curve_fit(gaussian_2d, xy, hist.T.ravel(), initial_guess)\n",
    "except RuntimeError as e:\n",
    "    warnings.warn(f\"Optimal parameters not found: {e}\")\n",
    "    popt = None \n",
    "if popt is not  None:\n",
    "    mu = [popt[0], popt[1]]\n",
    "    cov_matrix = [[popt[2], popt[4]], [popt[4], popt[3]]]\n",
    "    e1, e2, rot = cov_to_axes_and_rotation(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "diff_info_out = base_linked_tray.with_suffix(\".diff\")\n",
    "info[\"average dwell time\"] = float(dwell_time*frame_to_s)\n",
    "if popt is not None:\n",
    "    info[\"diff_long_nm_nm_s\"] = float(e1*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"diff_short_nm_nm_s\"] = float(e2*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"time_per_1000nm_s_long_axis\"] = 1000 * 1000 / info[\"diff_long_nm_nm_s\"] / 2\n",
    "    info[\"mean_step_nm_s\"] = float(np.sqrt(2 * info[\"diff_long_nm_nm_s\"] * frame_to_s) / frame_to_s)\n",
    "    info[\"normality_str\"] = normal_str\n",
    "    info[\"anderson_test\"] = anderson_data\n",
    "    info[\"mu_x\"] = float(round(mu[0], 3))\n",
    "    info[\"mu_y\"] = float(round(mu[1], 3))\n",
    "    info[\"sigma_x\"] = float(round(cov_matrix[0][0], 3))\n",
    "    info[\"sigma_y\"] = float(round(cov_matrix[1][1], 3))\n",
    "    info[\"sigma_xy\"] = float(round(cov_matrix[0][1], 3))\n",
    "write_yaml(info, diff_info_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if popt is not None:\n",
    "    print(normal_str)\n",
    "    print(f'the means of multivariate normal distrubution are: mu(dx) = {mu[0]:.3f}, mu(dy) = {mu[1]:.3f}')\n",
    "    print(f'the standard deviations of the multivariate normal distribution are: sigma(dx) = {cov_matrix[0][0]:.3f}, sigma(dy) = {cov_matrix[1][1]:.3f}')\n",
    "    print(f'the covariance of the multivariate normal distribution is: sigma(dxdy) = {cov_matrix[0][1]:.3f}')\n",
    "    print(\"Diff along the long axis (in nm^2/s): \", info[\"diff_long_nm_nm_s\"])\n",
    "    print(\"Diff along the short axis (in nm^2/s): \", info[\"diff_short_nm_nm_s\"])\n",
    "    print(\"time per 1000nm (s): \", info[\"time_per_1000nm_s_long_axis\"])\n",
    "    print(\"mean step (nm/s) along the long axis:\", info[\"mean_step_nm_s\"])\n",
    "\n",
    "    z = gaussian_2d(xy, *popt)\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224, projection='3d')\n",
    "plt.sca(ax1)\n",
    "tray.length.hist()\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Histogram of trajectory steps\")\n",
    "plt.sca(ax2)\n",
    "steps.plot.scatter(\"dx\", \"dy\", alpha=0.1, ax=ax2)\n",
    "plt.title(\"Size of steps\")\n",
    "plt.sca(ax3)\n",
    "plt.hist2d(x,y, bins=bins, density=True)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "if popt is not None:\n",
    "    plt.contour(x_grid, y_grid, z.reshape(x_grid.shape), cmap='viridis')\n",
    "plt.colorbar(label='probability density')\n",
    "plt.xlabel('dx')\n",
    "plt.ylabel('dy')\n",
    "plt.title('probability density of step sizes - contour plot')\n",
    "if popt is not None:\n",
    "    plt.sca(ax4)\n",
    "    ax4.plot_surface(x_grid, y_grid, z.reshape(x_grid.shape), cmap='viridis')\n",
    "    plt.xlabel('dx')\n",
    "    plt.ylabel('dy')\n",
    "    ax4.set_zlabel('probability')\n",
    "    plt.title('Probability density of step sizes - surface plot')\n",
    "\n",
    "fig.savefig(f'{out_dir}/{basename}_2d_fit.png')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04975a750d0d94b70e65c12bed027ac01c971320ec0c311113029c4e52a73e0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('picasso')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
