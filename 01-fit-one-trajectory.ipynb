{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import skimage.io as skio\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "from pathlib import Path\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "in_file = r\"examples/20240206-114518_WT_aligned_drift_corrected.tif\"\n",
    "out_dir = \"./out\"\n",
    "\n",
    "fit_method = \"lq\"\n",
    "box_side_length = 5\n",
    "drift = 0\n",
    "min_gradient = 600\n",
    "\n",
    "max_link_displacement_px = 3\n",
    "min_tray_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basename = os.path.basename(in_file)\n",
    "out_dir = Path(out_dir)\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_only_walkers_on_fibre_trajectory(in_file, out_dir / basename)\n",
    "basename_noext, ext = os.path.splitext(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['HDF5_DISABLE_VERSION_CHECK']='0'\n",
    "#TOOD add out parameter\n",
    "!python -m picasso localize {out_dir/basename} --fit-method {fit_method} --box-side-length {box_side_length}  --gradient {min_gradient} --drift {drift}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack -- for now just rename the out file. This is dangerous in multithreaded environment.\n",
    "out_locs = out_dir / (basename_noext + \"_locs.hdf5\")\n",
    "new_suffix = (\n",
    "    f\"__locs_{fit_method}_box{box_side_length}_grad{min_gradient}_drift{drift}.hdf5\"\n",
    ")\n",
    "new_out_locs = out_dir / (basename_noext + new_suffix)\n",
    "print(new_out_locs)\n",
    "out_locs.with_suffix(\".yaml\").rename(new_out_locs.with_suffix(\".yaml\"))\n",
    "out_locs.rename(new_out_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_link_displacement_px in [1]:\n",
    "    locs = pd.read_hdf(new_out_locs, \"locs\")\n",
    "    locs[\"mass\"] = locs.photons\n",
    "\n",
    "    tray = tp.link(locs, max_link_displacement_px)\n",
    "\n",
    "    # count the length of trajectories\n",
    "    tray_by_particle = tray.groupby([\"particle\"])\n",
    "    tray[\"length\"] = tray_by_particle[\"particle\"].transform(\"count\")\n",
    "\n",
    "    # tray.length.hist()\n",
    "    print(\"mean drift \", tp.compute_drift(tray).mean())\n",
    "\n",
    "    # Exclude very short trays\n",
    "    tray = tray.query(f\"length>={min_tray_length}\")\n",
    "\n",
    "    steps = tray.groupby([\"particle\"]).apply(get_steps_from_df)\n",
    "    steps[\"step_len\"] = np.sqrt(steps.dx**2 + steps.dy**2)\n",
    "    print(len(steps))\n",
    "\n",
    "    suffix = f\"__link{max_link_displacement_px}_trajlen{min_tray_length}\"\n",
    "    base_linked_tray = Path(f'{new_out_locs.with_suffix(\"\")}{suffix}')\n",
    "    tray_out = base_linked_tray.with_suffix(\".traj.csv.gz\")\n",
    "    tray.to_csv(tray_out)\n",
    "    steps_out = base_linked_tray.with_suffix(\".steps.csv.gz\")\n",
    "    steps.to_csv(steps_out)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(5, 15))\n",
    "\n",
    "    plt.sca(axes[0])\n",
    "    tray.length.hist()\n",
    "    plt.xlabel(\"Trajectory Length\")\n",
    "    plt.title(\"Histogram of trajectory steps\")\n",
    "\n",
    "    plt.sca(axes[1])\n",
    "    steps.plot.scatter(\"dx\", \"dy\", ax=axes[1])\n",
    "    plt.title(\"Size of steps\")\n",
    "\n",
    "    plt.sca(axes[2])\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    from scipy.stats import norm\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    step_len_signed = steps.step_len * np.random.choice((-1, 1), size=len(steps))\n",
    "    # Generate some data for this demonstration.\n",
    "    data = step_len_signed\n",
    "\n",
    "    # Fit a normal distribution to the data:\n",
    "    mu, std = norm.fit(data)\n",
    "    print(\"Diff: \", std**2 / 2)\n",
    "\n",
    "    # Plot the histogram.\n",
    "    plt.hist(data, bins=15, density=True, alpha=0.6, color=\"g\")\n",
    "\n",
    "    # Plot the PDF.\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    plt.plot(x, p, \"k\", linewidth=2)\n",
    "    title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    # perform Anderson-Darling Test\n",
    "    from scipy.stats import anderson\n",
    "\n",
    "    anderson_data = anderson(data)\n",
    "\n",
    "    is_normal = anderson_data.statistic < anderson_data.critical_values[1]\n",
    "    if not is_normal:\n",
    "        normal_str = f\"NOT NORMAL AT {anderson_data.significance_level[1]}%\"\n",
    "    else:\n",
    "        normal_str = f\"normal at {anderson_data.significance_level[1]}%\"\n",
    "    print(normal_str)\n",
    "    plt.xlabel(\"Step size (px)\\n\" + normal_str)\n",
    "    plt.savefig(base_linked_tray.with_suffix(\".png\"))\n",
    "\n",
    "    info = {}\n",
    "    info[\"diff_1D_px_px_frame\"] = float(get_diff_from_steps(steps))\n",
    "    print(\"Diff (in px^2/frame): \", info[\"diff_1D_px_px_frame\"])\n",
    "\n",
    "    px_to_nm = 110\n",
    "    frame_to_s = 0.665\n",
    "\n",
    "    info[\"diff_1D_nm_nm_s\"] = (\n",
    "        info[\"diff_1D_px_px_frame\"] * px_to_nm * px_to_nm / frame_to_s\n",
    "    )\n",
    "    print(\"Diff (in nm^2/s): \", info[\"diff_1D_nm_nm_s\"])\n",
    "    info[\"time_per_1000nm_s\"] = 1000 * 1000 / info[\"diff_1D_nm_nm_s\"] / 2\n",
    "    print(\"time per 1000nm (s): \", info[\"time_per_1000nm_s\"])\n",
    "\n",
    "    info[\"mean_step_nm_s\"] = float(\n",
    "        np.sqrt(2 * info[\"diff_1D_nm_nm_s\"] * frame_to_s) / frame_to_s\n",
    "    )\n",
    "    print(\"mean step (nm/s):\", info[\"mean_step_nm_s\"])\n",
    "\n",
    "    diff_info_out = base_linked_tray.with_suffix(\".diff\")\n",
    "\n",
    "    info[\"normality_str\"] = normal_str\n",
    "    info[\"anderson_test\"] = anderson_data\n",
    "\n",
    "    write_yaml(info, diff_info_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(steps.dx, steps.dy, bins=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, x_edges, y_edges = np.histogram2d(steps.dx, steps.dy, bins=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal \n",
    "mean, cov = multivariate_normal.fit(np.array([steps.dx, steps.dy]).T)\n",
    "normal_dist = multivariate_normal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist.pdf([0,0])\n",
    "\n",
    "eigen_values, eigen_vectors = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = (multivariate_normal)\n",
    "\n",
    "x_centers = (x_edges[:-1] + x_edges[1:]) / 2\n",
    "y_centers = (y_edges[:-1] + y_edges[1:]) / 2\n",
    "x_mesh, y_mesh = np.meshgrid(x_centers, y_centers)  # Creates two 2D arrays\n",
    "xy_combined = np.array([x_mesh.ravel(), y_mesh.ravel()]).T\n",
    "\n",
    "\n",
    "plt.imshow(hist, extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]], origin='lower')\n",
    "plt.contour(x_mesh, y_mesh, normal_dist.pdf(xy_combined).reshape(75, 75), colors='k', alpha=0.5)\n",
    "plt.quiver(mean[0], mean[1], eigen_vectors[0,0], eigen_vectors[0,1], color='red')\n",
    "plt.quiver(mean[0], mean[1], eigen_vectors[1,0], eigen_vectors[1,1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten longest trajectories\n",
    "top_ten = list(tray.sort_values(by='length', ascending=False).groupby('particle', sort=False).first().index[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(ids: list):\n",
    "    for traj_id in ids:\n",
    "        one_traj = tray.query(f'particle=={traj_id}')\n",
    "        one_traj.plot('x', 'y', label=traj_id, ax=plt.gca() )\n",
    "\n",
    "plot_trajectory(top_ten[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL = np.diag(eigen_values)\n",
    "V = eigen_vectors\n",
    "V_inv = np.linalg.inv(V)\n",
    "V@VAL@V_inv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04975a750d0d94b70e65c12bed027ac01c971320ec0c311113029c4e52a73e0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('picasso')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
