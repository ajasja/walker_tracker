{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import skimage.io as skio\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import trackpy as tp\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from matplotlib.tri import Triangulation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import anderson\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = r\"C:\\Users\\lizau\\Desktop\\walker_tracker_for_article\\walker_tracker\\example\"\n",
    "in_files = glob.glob(f'{file_directory}/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method = \"lq\"\n",
    "box_side_length = 7\n",
    "drift = 0\n",
    "min_gradient = 800\n",
    "px_to_nm = 72\n",
    "frame_to_s = 0.25\n",
    "\n",
    "max_link_displacement_px = 2\n",
    "max_gap = 0\n",
    "min_tray_length = 3\n",
    "min_fibre_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell: \n",
    "#   identifies walkers on the track\n",
    "#   localizes the walkers\n",
    "#   calculates the walkers' steps and trajectories\n",
    "#   calculates the parameters of a 2D Gaussian distribution for the walkers' steps\n",
    "#   plots the 2D distribution\n",
    "#   calculates the diffusion coefficient in each dimension, average dwell time and the time the walker would need to cover the length of 1 micrometre\n",
    "\n",
    "diff_coeff_e1 = []\n",
    "diff_coeff_e2 = []\n",
    "time_1000_nm = []\n",
    "dwell_t = []\n",
    "file_basename = []\n",
    "for file in in_files:\n",
    "    basename = os.path.basename(file)\n",
    "    file_basename += [basename]\n",
    "    basename_noext, ext = os.path.splitext(basename)\n",
    "    out_dir = Path(f'{file_directory}\\out_parametric')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    take_only_walkers_on_fibre_trajectory(file, out_dir / basename_noext, min_fibre_size=min_fibre_size)\n",
    "    new_out_locs = fit_single_molecules(\n",
    "        out_dir,\n",
    "        basename,\n",
    "        fit_method=fit_method,\n",
    "        box_side_length=box_side_length,\n",
    "        drift=drift,\n",
    "        min_gradient=min_gradient,\n",
    "        px_to_nm=px_to_nm,\n",
    "    )\n",
    "    locs = pd.read_hdf(new_out_locs, \"locs\")\n",
    "    locs[\"mass\"] = locs.photons\n",
    "    \n",
    "    tray = tp.link(locs, max_link_displacement_px, memory=max_gap) \n",
    "    \n",
    "    # Optional: if you want to rotate the data (doesn't change the fit)\n",
    "   \n",
    "    '''theta_deg = 180\n",
    "    theta = np.radians(theta_deg)\n",
    "    \n",
    "    # Rotation matrix\n",
    "    R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                [np.sin(theta),  np.cos(theta)]])\n",
    "\n",
    "    # Apply rotation\n",
    "    xy = tray[[\"x\", \"y\"]].values\n",
    "    rotated_xy = xy @ R.T   # matrix multiply\n",
    "\n",
    "    tray[[\"x\", \"y\"]] = rotated_xy'''\n",
    "\n",
    "    # Count the length of trajectories\n",
    "    tray_by_particle = tray.groupby([\"particle\"])\n",
    "    tray[\"length\"] = tray_by_particle[\"particle\"].transform(\"count\")\n",
    "    dwell_time = tray[\"length\"].mean()\n",
    "\n",
    "    # Exclude very short trays\n",
    "    tray = tray.query(f\"length>={min_tray_length}\")\n",
    "\n",
    "    # Calculate steps\n",
    "    steps = tray.groupby([\"particle\"]).apply(get_steps_from_df)\n",
    "    steps[\"step_len\"] = np.sqrt(steps.dx**2 + steps.dy**2)\n",
    "\n",
    "    # Save trajectories and steps\n",
    "    tray_out = Path(f'{out_dir}/{basename_noext}_link{max_link_displacement_px}_traylen{min_tray_length}.tray.csv')\n",
    "    tray.to_csv(tray_out)\n",
    "    steps_out = Path(f'{out_dir}/{basename_noext}.steps.csv')\n",
    "    steps.to_csv(steps_out)\n",
    "\n",
    "    # Distribution_check = []\n",
    "    steps_matrix = steps[['dx', 'dy']].to_numpy()\n",
    "    num_columns = steps_matrix.shape[1]  \n",
    "    normal_str = ''\n",
    "    for var_idx in range(num_columns):\n",
    "        anderson_data = anderson(steps_matrix[:, var_idx])\n",
    "        is_normal = anderson_data.statistic < anderson_data.critical_values[1]\n",
    "        #distribution_check += [is_normal]\n",
    "        if not is_normal:\n",
    "            normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} NOT normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "        else:\n",
    "            normal = f\"variable {f'dx' if var_idx == 0 else f'dy'} normally distributed at {anderson_data.significance_level[1]}%\\n\"\n",
    "        normal_str += normal \n",
    "\n",
    "    # Calculate the parameters of the multivariate normal distribution\n",
    "    mod = MultivariateNormal()\n",
    "    mod.fit(steps_matrix)\n",
    "\n",
    "    # Calculate the e1 and e2\n",
    "    cov_matrix = mod.sig_\n",
    "    e1, e2, rot = cov_to_axes_and_rotation(cov_matrix)\n",
    "\n",
    "    # Save info\n",
    "    info = {}\n",
    "    \n",
    "    diff_info_out = Path(f'{out_dir}/{basename}.diff')\n",
    "    info[\"average_dwell_time\"] = float(dwell_time*frame_to_s)\n",
    "    info[\"diff_long_nm_nm_s\"] = float(e1*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"diff_short_nm_nm_s\"] = float(e2*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"diff_long_nm_nm_s\"] = float(e1*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"diff_short_nm_nm_s\"] = float(e2*(px_to_nm**2)/(2*frame_to_s))\n",
    "    info[\"time_per_1000nm_s_long_axis\"] = 1000 * 1000 / info[\"diff_long_nm_nm_s\"] / 2\n",
    "    info[\"mean_step_nm_s\"] = float(np.sqrt(2 * info[\"diff_long_nm_nm_s\"] * frame_to_s) / frame_to_s)\n",
    "    info[\"normality_str\"] = normal_str\n",
    "    info[\"anderson_test\"] = anderson_data\n",
    "    info[\"mu_x\"] = float(round(mod.u_[0][0], 3))\n",
    "    info[\"mu_y\"] = float(round(mod.u_[1][0], 3))\n",
    "    info[\"sigma_x\"] = float(round(cov_matrix[0][0], 3))\n",
    "    info[\"sigma_y\"] = float(round(cov_matrix[1][1], 3))\n",
    "    info[\"sigma_xy\"] = float(round(cov_matrix[0][1], 3))\n",
    "    write_yaml(info, diff_info_out)\n",
    "\n",
    "    diff_coeff_e1 += [info[\"diff_long_nm_nm_s\"]]\n",
    "    diff_coeff_e2 += [info[\"diff_short_nm_nm_s\"]]\n",
    "    time_1000_nm += [info[\"time_per_1000nm_s_long_axis\"]]\n",
    "    dwell_t += [info[\"average_dwell_time\"]]\n",
    "    \n",
    "    z = mod.prob(steps_matrix)\n",
    "    x = steps['dx']\n",
    "    y = -steps['dy']\n",
    "    triang = Triangulation(x, y)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.plot(x,y, '.', alpha = 0.2)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.tricontour(triang, z.ravel(), cmap = 'viridis')\n",
    "    plt.colorbar(label='probability density') \n",
    "    plt.xlabel('dx')\n",
    "    plt.ylabel('dy')\n",
    "    plt.title('Probability density of step sizes - contour plot')\n",
    "\n",
    "    fig.savefig(f'{out_dir}/{basename_noext}_2d_fit.png')\n",
    "    '''\n",
    "    x = steps['dx'].values\n",
    "    y = steps['dy'].values\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.plot(x, y, '.', alpha=0.2)\n",
    "\n",
    "    # 2. Build a regular grid\n",
    "    x_grid = np.linspace(x.min()-0.5, x.max()+0.5, 200)\n",
    "    y_grid = np.linspace(y.min()-0.5, y.max()+0.5, 200)\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "    grid_points = np.column_stack([X.ravel(), Y.ravel()])\n",
    "\n",
    "    # 3. Evaluate your model probability on the grid\n",
    "    Z = mod.prob(grid_points).reshape(X.shape)\n",
    "\n",
    "    # 4. Contour plot\n",
    "    plt.contour(X, Y, Z, levels=10, cmap='viridis')\n",
    "    plt.colorbar(label='probability density')\n",
    "\n",
    "    # 5. Labels and aspect ratio\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('dx')\n",
    "    plt.ylabel('dy')\n",
    "    plt.title('Probability density of step sizes - contour plot')\n",
    "    fig.savefig(f'{out_dir}/{basename_noext}_2d_fit.png')'''\n",
    "\n",
    "diff_params = {'BASENAME': file_basename, 'e1': diff_coeff_e1, 'e2': diff_coeff_e2, 'time_1000_nm': time_1000_nm, 'average_dwell_time': dwell_t}\n",
    "diff_params_df = pd.DataFrame(diff_params)\n",
    "diff_params_df.to_csv(f'{out_dir}/diff_info.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageAligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
